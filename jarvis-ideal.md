# Jarvis Ideal

## What i want
- my own version of [clawdbot](https://github.com/clawdbot/clawdbot): leaner, focused on AI assistance and research.
- using the insight that agents work better with filesystem as database for managing context:
    - [agentfs](https://github.com/tursodatabase/agentfs)
    - [Everything is a file](https://turso.tech/blog/nothing-new-under-the-sun)
- keep control of my own memories (context generated by the agent from my chat history):
    - best memory feature is from chatgpt
    - i want to be able to move my memories files around
    - i want the memories files to be easily queriable

## Features

### Conversation Modes

- **Fast:** fast general chat. Focus on speed and cost. Shorter answers. Usually less than ~700 chars.
- **Thinking:** general chat with more deeply researched, long, answers. Focus on grounded answers. The user would use this mode for complex topics or multi-step answers.
- Both modes should show the sources used for the answer. The sources should be put as footnotes, using academic conventions to show references. For example: "Pedro √Ålvares Cabral descobriu o Brasil em 1500[1]".
- Both modes should allow the user to attach PDF files as sources to the answer, in addition to the own LLM internal search process. The same applies to "Deep Research" mode.

### Deep Research

- Used for research report generation (8+ pages) as PDF files.
- Reports MUST be heavily grounded in high quality sources:
    1. High quality academic research papers: look for meta-analyses, high powered studies, low p-values accompanied by high effect sizes. I want robust, methodologically sound research, not p-hacked ones.
    2. Average quality academic research papers
    3. Books
    4. High traffic websites (news portals, wikipedia, archive)
    5. Social networks/private blogs: reddit, X (prev. Twitter), small blogs, etc.
- Reports should follow the traditional academic research papers sections (IMRaD convention):
    - **Introduction:** Sets the stage. It provides background information, identifies a "gap" in existing knowledge, and ends with a clear thesis statement or research question.
    - **Literature review:** Often nested within the Introduction, this section summarizes previous research to show how your work builds upon or challenges existing knowledge.
    - **Methodology:** The "how-to" guide. This section describes the participants, materials, and procedures used. It must be detailed enough for another researcher to replicate your study.
    - **Results:** The "what happened" section. It presents the raw findings and data (often using tables and figures) without any interpretation or opinion.
    - **Discussion:** The "what it means" section. Here, you interpret your findings, explain how they relate to the original research question, and compare them to previous studies.
    - **Conclusion:** Summarizes the main points and suggests the broader implications of the work. Unlike the Discussion, this section often focuses on the "big picture" and future research directions.
    - **References:** An alphabetized list of every source cited in your paper, formatted according to a specific style guide (like APA, MLA, or Chicago).
- This is an **asynchronous task**: the user should be informed we will perform the deep research in the background and will notify the user when its done.
- [Elicit](https://elicit.com/blog/systematic-review) is my gold standard for deep research. It seems they use LLM agents to perform deep research as a multi-step task. More about Elicit's approach: [Elicit's report](https://elicit.com/blog/introducing-elicit-reports), [Research agents](https://elicit.com/blog/introducing-research-agent-workflows)
- Other open source implementations to look for:
    - [Langchain Open Source Deep Research](https://github.com/langchain-ai/open_deep_research) - a bit outdated; also langchain tends to be overly complex.
    - **[gpt researcher](https://github.com/assafelovic/gpt-researcher) - i skimmed the repo; it seems the most promising open source alternative for us.**

## About agents context
- [How context fail](https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html)
- [Oops, you wrote a database!](https://dx.tips/oops-database)
- [How to build agents with filesystems and bash](https://vercel.com/blog/how-to-build-agents-with-filesystems-and-bash)

## Books and Scientific Papers for free
- [Annas Archive API](https://annas-archive.li/faq#api): 
*We have one stable JSON API for members, for getting a fast download URL: [/dyn/api/fast_download.json](https://annas-archive.li/dyn/api/fast_download.json) (documentation within JSON itself).
For other use cases, such as iterating through all our files, building custom search, and so on, we recommend [generating](https://software.annas-archive.li/AnnaArchivist/annas-archive/-/blob/main/data-imports/README.md) or [downloading](https://annas-archive.li/torrents#aa_derived_mirror_metadata) our ElasticSearch and MariaDB databases. The raw data can be manually explored through JSON files](https://annas-archive.li/db/aarecord_elasticsearch/md5:8336332bf5877e3adbfb60ac70720cd5.json.html). Our raw torrents list can be downloaded as [JSON](https://annas-archive.li/dyn/torrents.json) as well.*
- [Semantic Scholar API](https://www.semanticscholar.org/product/api/tutorial): if we use an API key, we get 1 rate per second limit. For our use its sufficient.